{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to RAG Applications\n",
    "\n",
    "This notebook creates a simple RAG (Retrieval-Augmented Generation) system to answer questions from a PDF document using an open-source model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = \"paul.pdf\"\n",
    "\n",
    "# We'll be using Llama 3.1 8B for this example.\n",
    "MODEL = \"mistral-nemo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PDF document\n",
    "\n",
    "Let's start by loading the PDF document and breaking it down into separate pages.\n",
    "\n",
    "<img src='images/documents.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 9\n",
      "Length of a page: 3272\n",
      "Content of a page: 10% a week. And while 110 may not seem much better than 100,\n",
      "if you keep growing at 10% a week you'll be surprised how big\n",
      "the numbers get. After a year you'll have 14,000 users, and after\n",
      "2 years you'll have 2 million.\n",
      "You'll be doing different things when you're acquiring users a\n",
      "thousand at a time, and growth has to slow down eventually. But\n",
      "if the market exists you can usually start by recruiting users\n",
      "manually and then gradually switch to less manual methods. [3]\n",
      "Airbnb is a classic example of this technique. Marketplaces are so\n",
      "hard to get rolling that you should expect to take heroic measures\n",
      "at first. In Airbnb's case, these consisted of going door to door in\n",
      "New York, recruiting new users and helping existing ones improve\n",
      "their listings. When I remember the Airbnbs during YC, I picture\n",
      "them with rolly bags, because when they showed up for tuesday\n",
      "dinners they'd always just flown back from somewhere.\n",
      "Fragile\n",
      "Airbnb now seems like an unstoppable juggernaut, but early on it\n",
      "was so fragile that about 30 days of going out and engaging in\n",
      "person with users made the difference between success and\n",
      "failure.\n",
      "That initial fragility was not a unique feature of Airbnb. Almost all\n",
      "startups are fragile initially. And that's one of the biggest things\n",
      "inexperienced founders and investors (and reporters and know-it-\n",
      "alls on forums) get wrong about them. They unconsciously judge\n",
      "larval startups by the standards of established ones. They're like\n",
      "someone looking at a newborn baby and concluding \"there's no\n",
      "way this tiny creature could ever accomplish anything.\"\n",
      "It's harmless if reporters and know-it-alls dismiss your startup.\n",
      "They always get things wrong. It's even ok if investors dismiss\n",
      "your startup; they'll change their minds when they see growth.\n",
      "The big danger is that you'll dismiss your startup yourself. I've\n",
      "seen it happen. I often have to encourage founders who don't see\n",
      "the full potential of what they're building. Even Bill Gates made\n",
      "that mistake. He returned to Harvard for the fall semester after\n",
      "starting Microsoft. He didn't stay long, but he wouldn't have\n",
      "returned at all if he'd realized Microsoft was going to be even a\n",
      "fraction of the size it turned out to be. [4]\n",
      "The question to ask about an early stage startup is not \"is this\n",
      "company taking over the world?\" but \"how big could this company\n",
      "get if the founders did the right things?\" And the right things\n",
      "often seem both laborious and inconsequential at the time.\n",
      "Microsoft can't have seemed very impressive when it was just a\n",
      "couple guys in Albuquerque writing Basic interpreters for a\n",
      "market of a few thousand hobbyists (as they were then called),\n",
      "but in retrospect that was the optimal path to dominating\n",
      "microcomputer software. And I know Brian Chesky and Joe\n",
      "Gebbia didn't feel like they were en route to the big time as they\n",
      "were taking \"professional\" photos of their first hosts' apartments.\n",
      "They were just trying to survive. But in retrospect that too was\n",
      "the optimal path to dominating a big market.\n",
      "How do you find users to recruit manually? If you build something\n",
      "to solve your own problems, then you only have to find your\n",
      "peers, which is usually straightforward. Otherwise you'll have to\n",
      "8/6/24, 11:04 AM Do Things that Don't Scale\n",
      "https://paulgraham.com/ds.html 2/9\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_FILE)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Number of pages: {len(pages)}\")\n",
    "print(f\"Length of a page: {len(pages[1].page_content)}\")\n",
    "print(\"Content of a page:\", pages[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the pages in chunks\n",
    "\n",
    "Pages are too long, so let's split pages into different chunks.\n",
    "\n",
    "<img src='images/splitter.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 23\n",
      "Length of a chunk: 1236\n",
      "Content of a chunk: took better advantage of it than Stripe. At YC we use the term\n",
      "\"Collison installation\" for the technique they invented. More\n",
      "diffident founders ask \"Will you try our beta?\" and if the answer is\n",
      "yes, they say \"Great, we'll send you a link.\" But the Collison\n",
      "brothers weren't going to wait. When anyone agreed to try Stripe\n",
      "they'd say \"Right then, give me your laptop\" and set them up on\n",
      "the spot.\n",
      "There are two reasons founders resist going out and recruiting\n",
      "users individually. One is a combination of shyness and laziness.\n",
      "They'd rather sit at home writing code than go out and talk to a\n",
      "bunch of strangers and probably be rejected by most of them.\n",
      "But for a startup to succeed, at least one founder (usually the\n",
      "CEO) will have to spend a lot of time on sales and marketing. [2]\n",
      "The other reason founders ignore this path is that the absolute\n",
      "numbers seem so small at first. This can't be how the big, famous\n",
      "startups got started, they think. The mistake they make is to\n",
      "underestimate the power of compound growth. We encourage\n",
      "every startup to measure their progress by weekly growth rate. If\n",
      "you have 100 users, you need to get 10 more next week to grow\n",
      "8/6/24, 11:04 AM Do Things that Don't Scale\n",
      "https://paulgraham.com/ds.html 1/9\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "\n",
    "chunks = splitter.split_documents(pages)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Length of a chunk: {len(chunks[1].page_content)}\")\n",
    "print(\"Content of a chunk:\", chunks[1].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the chunks in a vector store\n",
    "\n",
    "We can now generate embeddings for every chunk and store them in a vector store.\n",
    "\n",
    "<img src='images/vectorstore.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a retriever\n",
    "\n",
    "We can use a retriever to find chunks in the vector store that are similar to a supplied question.\n",
    "\n",
    "<img src='images/retriever.png' width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3167e2ed-a922-4262-94a7-437eb86c1585', metadata={'source': 'paul.pdf', 'page': 2}, page_content=\"in charge of their narrow domain of building things, rather than\\nrunning the whole show. You can be ornery when you're Scotty,\\nbut not when you're Kirk.\\nAnother reason founders don't focus enough on individual\\ncustomers is that they worry it won't scale. But when founders of\\nlarval startups worry about this, I point out that in their current\\nstate they have nothing to lose. Maybe if they go out of their way\\nto make existing users super happy, they'll one day have too\\nmany to do so much for. That would be a great problem to have.\\nSee if you can make it happen. And incidentally, when it does,\\nyou'll find that delighting customers scales better than you\\nexpected. Partly because you can usually find ways to make\\nanything scale more than you would have predicted, and partly\\nbecause delighting customers will by then have permeated your\\nculture.\\nI have never once seen a startup lured down a blind alley by\\ntrying too hard to make their initial users happy.\\nBut perhaps the biggest thing preventing founders from realizing\\nhow attentive they could be to their users is that they've never\\nexperienced such attention themselves. Their standards for\\ncustomer service have been set by the companies they've been\\ncustomers of, which are mostly big ones. Tim Cook doesn't send\\nyou a hand-written note after you buy a laptop. He can't. But you\\ncan. That's one advantage of being small: you can provide a level\\nof service no big company can. [6]\"),\n",
       " Document(id='4c830df3-9c75-4c96-848f-635c245dfd4c', metadata={'source': 'paul.pdf', 'page': 3}, page_content='Experience\\nI was trying to think of a phrase to convey how extreme your\\nattention to users should be, and I realized Steve Jobs had\\nalready done it: insanely great. Steve wasn\\'t just using \"insanely\"\\nas a synonym for \"very.\" He meant it more literally — that one\\nshould focus on quality of execution to a degree that in everyday\\nlife would be considered pathological.\\nAll the most successful startups we\\'ve funded have, and that\\nprobably doesn\\'t surprise would-be founders. What novice\\nfounders don\\'t get is what insanely great translates to in a larval\\nstartup. When Steve Jobs started using that phrase, Apple was\\nalready an established company. He meant the Mac (and its\\ndocumentation and even packaging — such is the nature of\\nobsession) should be insanely well designed and manufactured.\\nThat\\'s not hard for engineers to grasp. It\\'s just a more extreme\\nversion of designing a robust and elegant product.\\nWhat founders have a hard time grasping (and Steve himself\\nmight have had a hard time grasping) is what insanely great\\nmorphs into as you roll the time slider back to the first couple\\nmonths of a startup\\'s life. It\\'s not the product that should be\\ninsanely great, but the experience of being your user. The product\\nis just one component of that. For a big company it\\'s necessarily\\nthe dominant one. But you can and should give users an insanely\\ngreat experience with an early, incomplete, buggy product, if you\\nmake up the difference with attentiveness.'),\n",
       " Document(id='9013acbc-e646-4561-85b7-a861b140b94e', metadata={'source': 'paul.pdf', 'page': 2}, page_content=\"of service no big company can. [6]\\nOnce you realize that existing conventions are not the upper\\nbound on user experience, it's interesting in a very pleasant way\\nto think about how far you could go to delight your users.\\n8/6/24, 11:04 AM Do Things that Don't Scale\\nhttps://paulgraham.com/ds.html 3/9\"),\n",
       " Document(id='4fc65166-79af-48ed-b2fd-cc34a135fd7c', metadata={'source': 'paul.pdf', 'page': 3}, page_content=\"students. In that form it only had a potential market of a few\\nthousand people, but because they felt it was really for them, a\\ncritical mass of them signed up. After Facebook stopped being for\\n8/6/24, 11:04 AM Do Things that Don't Scale\\nhttps://paulgraham.com/ds.html 4/9\")]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"What can you get away with when you only have a small number of users?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the model\n",
    "\n",
    "We'll be using Ollama to load the local model in memory. After creating the model, we can invoke it with a question to get the response back.\n",
    "\n",
    "<img src='images/model.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The current President of the United States is Joseph R. (Joe) Biden Jr. He took office on January 20, 2021. Here's a brief overview:\\n\\n- Full Name: Joseph Robinette Biden Jr.\\n- Born: November 20, 1942\\n- Political Party: Democratic\\n- Previous Offices:\\n  - 47th Vice President of the United States (2009–2017)\\n  - U.S. Senator from Delaware (1973–2009)\", additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-01-05T14:18:30.9367209Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 3125646200, 'load_duration': 10904800, 'prompt_eval_count': 12, 'prompt_eval_duration': 142000000, 'eval_count': 116, 'eval_duration': 2971000000}, id='run-497f2ad9-e87c-4b9d-9d40-4a4b6e3e9bc2-0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=MODEL, temperature=0)\n",
    "model.invoke(\"Who is the president of the United States?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the model's response\n",
    "\n",
    "The response from the model is an `AIMessage` instance containing the answer. We can extract the text answer by using the appropriate output parser. We can connect the model and the parser using a chain.\n",
    "\n",
    "<img src='images/parser.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of the United States is Joseph R. (Joe) Biden Jr. He took office on January 20, 2021. Here's a brief overview:\n",
      "\n",
      "- Full Name: Joseph Robinette Biden Jr.\n",
      "- Born: November 20, 1942\n",
      "- Political Party: Democratic\n",
      "- Previous Offices:\n",
      "  - 47th Vice President of the United States (2009–2017)\n",
      "  - U.S. Senator from Delaware (1973–2009)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "print(chain.invoke(\"Who is the president of the United States?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a prompt\n",
    "\n",
    "In addition to the question we want to ask, we also want to provide the model with the context from the PDF file. We can use a prompt template to define and reuse the prompt we'll use with the model.\n",
    "\n",
    "\n",
    "<img src='images/prompt.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an assistant that provides answers to questions based on\n",
      "a given context. \n",
      "\n",
      "Answer the question based on the context. If you can't answer the\n",
      "question, reply \"I don't know\".\n",
      "\n",
      "Be as concise as possible and go straight to the point.\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an assistant that provides answers to questions based on\n",
    "a given context. \n",
    "\n",
    "Answer the question based on the context. If you can't answer the\n",
    "question, reply \"I don't know\".\n",
    "\n",
    "Be as concise as possible and go straight to the point.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the prompt to the chain\n",
    "\n",
    "We can now chain the prompt with the model and the parser.\n",
    "\n",
    "<img src='images/chain1.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\": \"Anna's sister is Susan\", \n",
    "    \"question\": \"Who is Susan's sister?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the retriever to the chain\n",
    "\n",
    "Finally, we can connect the retriever to the chain to get the context from the vector store.\n",
    "\n",
    "<img src='images/chain2.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the chain to answer questions\n",
    "\n",
    "Finally, we can use the chain to ask questions that will be answered using the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What can you get away with when you only have a small number of users?\n",
      "Answer: You can provide a level of service no big company can.\n",
      "*************************\n",
      "\n",
      "Question: What's the most common unscalable thing founders have to do at the start?\n",
      "Answer: Providing insanely great user experience with an early, incomplete product through attentiveness.\n",
      "*************************\n",
      "\n",
      "Question: What's one of the biggest things inexperienced founders and investors get wrong about startups?\n",
      "Answer: Inexperienced founders often don't realize how attentive they could be to their users.\n",
      "*************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What can you get away with when you only have a small number of users?\",\n",
    "    \"What's the most common unscalable thing founders have to do at the start?\",\n",
    "    \"What's one of the biggest things inexperienced founders and investors get wrong about startups?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print(\"*************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How can you create w wifi hotspot on Jetpack 5.1.2?\n",
      "Answer: I don't know\n",
      "*************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"How can you create w wifi hotspot on Jetpack 5.1.2?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print(\"*************************\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
